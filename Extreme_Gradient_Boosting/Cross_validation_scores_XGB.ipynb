{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab4c158-04a9-49d1-80dc-76ada6057f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn) (3.3.0)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.25.2)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Using cached nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.12.0)\n",
      "Using cached xgboost-2.1.3-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Using cached nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "Installing collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.23.4 xgboost-2.1.3\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (2.10.2)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from numexpr) (1.25.2)\n",
      "Best Parameters from Grid Search:\n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 600, 'reg_lambda': 1, 'subsample': 1.0}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64 28]\n",
      " [23 14]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        92\n",
      "           1       0.33      0.38      0.35        37\n",
      "\n",
      "    accuracy                           0.60       129\n",
      "   macro avg       0.53      0.54      0.53       129\n",
      "weighted avg       0.62      0.60      0.61       129\n",
      "\n",
      "\n",
      "Overall Cross-Validation Scores (Training Set):\n",
      "Scores: [0.70547945 0.69863014 0.7260274  0.7862069  0.79310345]\n",
      "Mean accuracy: 0.7418894662257912\n",
      "Variance: 0.0016071141036336973\n",
      "\n",
      "Cross-Validation Scores by Gender:\n",
      "\n",
      "Gender: Male\n",
      "Scores: [0.66101695 0.72881356 0.76271186 0.84482759 0.70689655]\n",
      "Mean accuracy: 0.740853302162478\n",
      "Variance: 0.0037920616111720476\n",
      "\n",
      "Gender: Female\n",
      "Scores: [0.64367816 0.74712644 0.67816092 0.75862069 0.79310345]\n",
      "Mean accuracy: 0.7241379310344828\n",
      "Variance: 0.003012286959968293\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "!pip install xgboost\n",
    "!pip install --upgrade numexpr\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'End_dataframe.csv'  # Update with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Features and target\n",
    "X = data[['Gender', 'Prior_Donation', 'Lcheek_max', 'Rcheek_max', 'nose_max', 'chin_max', 'below_nose_max', 'HRV_minmax']]\n",
    "y = data['VVR_Encoded']  # Assuming 'VVR_Encoded' is the target variable\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to balance the classes in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the XGBoost model and parameter grid for Grid Search\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 600, 800],  \n",
    "    'max_depth': [6, 9],  \n",
    "    'learning_rate': [0.01, 0.1],  \n",
    "    'subsample': [0.8, 1.0],  \n",
    "    'colsample_bytree': [0.8, 1.0],  \n",
    "    'reg_lambda': [1, 10],\n",
    "}\n",
    "\n",
    "# Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=0)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best model from Grid Search\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best Parameters from Grid Search:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Overall cross-validation scores (on training set)\n",
    "cv_scores = cross_val_score(best_xgb, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_variance = np.var(cv_scores)\n",
    "\n",
    "print(\"\\nOverall Cross-Validation Scores (Training Set):\")\n",
    "print(\"Scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", cv_mean)\n",
    "print(\"Variance:\", cv_variance)\n",
    "\n",
    "# Cross-validation scores by Gender\n",
    "gender_labels = {1: 'Male', 2: 'Female'}\n",
    "print(\"\\nCross-Validation Scores by Gender:\")\n",
    "\n",
    "for gender, gender_name in gender_labels.items():\n",
    "    # Filter data by gender\n",
    "    gender_mask = X_train_resampled['Gender'] == gender\n",
    "    X_gender = X_train_resampled[gender_mask].drop(columns='Gender')  # Drop Gender column for training\n",
    "    y_gender = y_train_resampled[gender_mask]\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores_gender = cross_val_score(best_xgb, X_gender, y_gender, cv=5, scoring='accuracy')\n",
    "    print(f\"\\nGender: {gender_name}\")\n",
    "    print(\"Scores:\", cv_scores_gender)\n",
    "    print(\"Mean accuracy:\", np.mean(cv_scores_gender))\n",
    "    print(\"Variance:\", np.var(cv_scores_gender))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
