{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed92783-1b0b-4bd3-a352-864d88db5ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/tmp/ipykernel_226/1841035760.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  temp_results = pd.concat([temp_results, phase_1_data, phase_2_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature maximum values for each phase saved to 'Max_Temp_Per_Phase.csv'.\n",
      "Temperature DataFrame with maximum values for each participant and phase:\n",
      "      ID    Phase  Lcheek_max  Rcheek_max   nose_max   chin_max  \\\n",
      "0      5  Phase 1   34.166066   33.825453  31.902261  35.591721   \n",
      "1      5  Phase 2   32.411108   31.885489  29.178592  32.803862   \n",
      "2      6  Phase 1   35.879672   35.084796  34.930636  35.351566   \n",
      "3      6  Phase 2   35.290003   36.863392  36.382971  36.107236   \n",
      "4      7  Phase 1   33.529776   34.483306  32.319753  34.155491   \n",
      "..   ...      ...         ...         ...        ...        ...   \n",
      "641  330  Phase 2   35.296979   35.215544  35.557796  35.759302   \n",
      "642  331  Phase 1   34.818268   34.952463  34.409054  34.759591   \n",
      "643  331  Phase 2   35.214667   35.351260  34.958756  35.273851   \n",
      "644  332  Phase 1   35.396243   34.995061  35.065544  35.913406   \n",
      "645  332  Phase 2   35.915842   35.348154  35.319248  35.390138   \n",
      "\n",
      "     below_nose_max  \n",
      "0         35.518991  \n",
      "1         31.002172  \n",
      "2         35.817322  \n",
      "3         36.294621  \n",
      "4         33.321274  \n",
      "..              ...  \n",
      "641       35.614745  \n",
      "642       34.552570  \n",
      "643       34.987278  \n",
      "644       35.432193  \n",
      "645       35.811826  \n",
      "\n",
      "[646 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file paths\n",
    "temp_file_path = 'Donor_temp_1-2_combined.csv'  \n",
    "\n",
    "# Read the temperature CSV file into a DataFrame\n",
    "df_temp = pd.read_csv(temp_file_path)\n",
    "\n",
    "# Check if the required columns exist in the temperature data\n",
    "required_columns = ['Participant_ID', 'Lcheek_max', 'Rcheek_max', 'nose_max', 'chin_max', 'below_nose_max']\n",
    "if not all(col in df_temp.columns for col in required_columns):\n",
    "    raise ValueError(f\"The input temperature data must contain the following columns: {required_columns}\")\n",
    "\n",
    "# Create an empty DataFrame to store the temperature results\n",
    "temp_results = pd.DataFrame(columns=[\n",
    "    \"ID\", \"Phase\", \"Lcheek_max\", \"Rcheek_max\", \n",
    "    \"nose_max\", \"chin_max\", \"below_nose_max\"\n",
    "])\n",
    "\n",
    "# Process each participant's data\n",
    "for participant_id, group in df_temp.groupby('Participant_ID'):\n",
    "    # Ensure the data is sorted if necessary (e.g., by time or index)\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    # Split the data into two phases of 1000 rows each\n",
    "    phase_1 = group.iloc[:1000]\n",
    "    phase_2 = group.iloc[1000:2000]\n",
    "\n",
    "    # Calculate the maximum for each phase\n",
    "    phase_1_max = phase_1[['Lcheek_max', 'Rcheek_max', 'nose_max', 'chin_max', 'below_nose_max']].max()\n",
    "    phase_2_max = phase_2[['Lcheek_max', 'Rcheek_max', 'nose_max', 'chin_max', 'below_nose_max']].max()\n",
    "\n",
    "    # Create a DataFrame for each phase maximum and append to the results\n",
    "    phase_1_data = pd.DataFrame({\n",
    "        \"ID\": [participant_id],\n",
    "        \"Phase\": [\"Phase 1\"],\n",
    "        \"Lcheek_max\": [phase_1_max['Lcheek_max']],\n",
    "        \"Rcheek_max\": [phase_1_max['Rcheek_max']],\n",
    "        \"nose_max\": [phase_1_max['nose_max']],\n",
    "        \"chin_max\": [phase_1_max['chin_max']],\n",
    "        \"below_nose_max\": [phase_1_max['below_nose_max']]\n",
    "    })\n",
    "\n",
    "    phase_2_data = pd.DataFrame({\n",
    "        \"ID\": [participant_id],\n",
    "        \"Phase\": [\"Phase 2\"],\n",
    "        \"Lcheek_max\": [phase_2_max['Lcheek_max']],\n",
    "        \"Rcheek_max\": [phase_2_max['Rcheek_max']],\n",
    "        \"nose_max\": [phase_2_max['nose_max']],\n",
    "        \"chin_max\": [phase_2_max['chin_max']],\n",
    "        \"below_nose_max\": [phase_2_max['below_nose_max']]\n",
    "    })\n",
    "\n",
    "    # Append the phase data to the temperature results DataFrame\n",
    "    temp_results = pd.concat([temp_results, phase_1_data, phase_2_data], ignore_index=True)\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = 'Max_Temp_Per_Phase.csv'  # New output file name\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "temp_results.to_csv(output_file_path, index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
